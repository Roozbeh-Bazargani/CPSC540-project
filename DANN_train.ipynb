{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test dataset loader\n",
    "import numpy as np\n",
    "from van_dataset import VanDataset\n",
    "\n",
    "dataset_path = '../data/VPC-10X'\n",
    "dataset = VanDataset(root_folder=dataset_path, slide_indexs=[1], augment=True)\n",
    "\n",
    "# visualize the dataset\n",
    "print(\"size of dataset: %d\\n\" % dataset.__len__())\n",
    "import matplotlib.pyplot as plt\n",
    "data = dataset.__getitem__(np.random.randint(0, dataset.__len__()))\n",
    "plt.figure()\n",
    "plt.imshow(data['image'][0])\n",
    "print(\"Class of the data: %d\\n\" % data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test dataset loader\n",
    "import numpy as np\n",
    "from colorado_dataset import CODataset\n",
    "\n",
    "dataset_path = '../data/Colorado-10X'\n",
    "dataset = CODataset(root_folder=dataset_path, slide_indexs=[1], augment=True)\n",
    "\n",
    "# visualize the dataset\n",
    "print(\"size of dataset: %d\\n\" % dataset.__len__())\n",
    "import matplotlib.pyplot as plt\n",
    "data = dataset.__getitem__(np.random.randint(0, dataset.__len__()))\n",
    "plt.figure()\n",
    "plt.imshow(data['image'][0])\n",
    "print(\"Class of the data: %d\\n\" % data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run training\n",
    "\n",
    "from train import *\n",
    "\n",
    "# example config file\n",
    "slices = get_colorado_slice('../data/Colorado-10X')\n",
    "print(\"slice numbers for Colorado dataset:\")\n",
    "print(slices)\n",
    "\n",
    "# sample config file for the training class\n",
    "cfg = {'tensorboard_dir': '', # dir to save tensorboard\n",
    "'saved_model_path': None,  # path of pretrained model\n",
    "'num_classes': 4,  # number of class\n",
    "'optimizer': 'Adam',  # name of optimizer\n",
    "'lr': 0.001,  # learning rate\n",
    "'wd': 0.005,  # weight decay\n",
    "'use_schedular': False,  # bool to select whether to use scheduler\n",
    "'epochs': 1,  # number of training epochs\n",
    "'source_dataset': '../data/VPC-10X',   # path to vancouver dataset\n",
    "'source_train_idx': [2,5,6,7],   # indexes of the slides used for training (van dataset)\n",
    "'source_val_idx': [3],   # indexes of the slides used for validation (van dataset)\n",
    "'source_test_idx': [1],   # indexes of the slides used for testing (van dataset)\n",
    "'batch_size': 2,  # batch size\n",
    "'augment': True,  # whether use classical cv augmentation\n",
    "'target_dataset': '../data/Colorado-10X',  # path to Colorado dataset\n",
    "'target_train_idx': slices[:-2],  # indexes of the slides used for training (CO dataset)\n",
    "'target_test_idx': slices[-2:],  # indexes of the slides used for testing (CO dataset)\n",
    "'num_workers': 1, # number of workers\n",
    "'val_criteria': 'overall_acc',  # criteria to keep the current best model, can be overall_acc, overall_f1, overall_auc, val_loss\n",
    "'checkpoints': 'checkpoints',  # dir to save the best model, training configurations and results\n",
    "'only_test': False  # select true if only want to do testing\n",
    "\n",
    "}\n",
    "\n",
    "# init trainer\n",
    "trainer = SimpleDANNTrain(cfg)\n",
    "# run trainer\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef126d996a71beda3b05b6ccdf6e49157cabd64aeaee14f5b7eed026f0b3dfd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('med_cv_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
